12/31/23
I'm only starting this devlog a couple of days into working on the first prototype of the ideas that I have for my game project, so here is a recap of the work I have done so far: 
    Read through good chunks of Godot's online documentation and some of the engine's weaknesses (None of which seemed to be too relevant to me - although I don't remember them)
    Worked through some of the "Your first 2D game" pages on the documentation, quickly getting sidetracked with my own movement logic and effects
    Started a 2D platforming game just to work out the built-in physics, collision and animation systems, and getting a glimpse of how TileMaps work.
    Started a prototype for what I want the actual dissertation project to look/work like, and so far I have made:
        Borrowed assets on a tilemap making up a level node
        A character controller node using the engine's built in CharacterBody Node, enabling easy movement and collision with the level as well as simple animation
        A fireball node that I can add to the Main node, handling its own collision, destruction and animations 
        A chest node which detects a player nearby and opens itself, and then despawns itself
        Lights attached to players, fireballs and chests with the occlusion layers to match on the TileMap, to create simple shadows across the level
        I've also toyed with various shader effects, creating a vignette for the whole canvas to make the level look less flat, as well as rasterization with dithering to make the game more visually interesting as well as to make the mismatched assets that I will be using less apparent: more limited colour palletes will help a lot, I imagine. I also have a shader created for the chest to flash when it's about to despawn, and I imagine it's a nice base to work off of for other things
    I've learned a lot about the structure of Godot's objects and various menus but it's going to be a while before I know about all the tools at my disposal and how they are best applied. I am very glad that the systems seem to be very compatible with ripping stuff out and restructuring things, because I still have no idea how to lay out the nodes in this game.

I was planning on making a devlog when I started development, just to ramble about things that I know I will forget regarding my writeup or ideas for the game. It'll be nice to get a Trello board once the project is fully in motion, but for now I just wanted to note a few things:
    The first big feature that I'm going to want to prototype is a bunch of nicely encapsulated spellcasting nodes, and then I'll be wanting to find out how to give them to the player in a gameplay sense - I think limited use cards would be fun and unique, but I have yet to see how fun it is. There are already a lot of good ideas about this on Google Docs, but that document is probably going to be made obsolete by this one.
    I'm probably not going to be working on procedural generation until the gameplay loop is solid, but I do need ideas about how to transition from area to area. I want the game to have a room structure, and I think it would be fun to have rooms larger than a single screen. For transitioning between them, I could use simple "teleport" doors for simplicity, but a real level structure would be more fun... and harder to implement with procedural generation. While fiddling with shaders I stumbled on a very interesting way to do screen transitions, which is to turn the quantization levels way down to 0 on my shader, change the screen, and then turn the quantization back up. I'm not sure if I want to keep the graphics the same as they are right now, with the low bit depth, but it could be an easy way to add some style to the game. I'm looking forward to toying with lighting and shaders a lot more, but the built-in lighting system doesn't look to enable a lot of variety, so I might have a lot of learning ahead of me for that one. The built-in stuff is pretty good by itself though!

23/1/24

I met with my supervisor yesterday, and we discussed due dates, deadlines, the self-imposed MVP deadline, referencing and where marks would come from in my dissertation. The outcome of the meeting was, expectedly, that I need to get to grips with Godot a little bit more, as well as create a detailed specification for my MVP as well as creating a timeline for when I would like to complete tasks by. 

In the last week or two, I have toyed around with restructuring my project to enable flexibility in development and prototyping, but I am not satisfied with what I've made so far.
The basis for this work has been Godot's Resources, as suggested by members of the Godot discord. I tried to make a Projectile and Weapon resource file, derive different types of weapons and projectiles from those resources and use the resources to instantiate weapon and projectile scenes into the game. 
This method falls short for modularity and fast prototyping because adding new attributes to resources is quite an involved process, and it is difficult to attach different behaviours to resources since they all need to be compatible with the same Projectile class. Having a different scene for each object seems to require less work and not much more repetition, since I don't plan on having that many different types of weapons or projectiles to begin with anyways. Fail fast!

I've done a little bit more work in understanding what a Godot class even is, so going forward I will try to use nodes, scripts and class extensions, since it is what I am familliar with and what seems most sensible right now. I'm sure I will find better methods later down the line, and that I will find a use for the resource system.

24/1/24

In the meeting we discussed that work done, dissertation coverage and mark weight will be loosely proportional, so I wonder if there should be a section dedicated to explaining my process of learning Godot, and the lessons that I took away from it. So far I've found that I need to lean into Nodes more, and really obey single-responsibility rules, as well as "Keep it Simple, Stupid."

I need to assess which elements would be a good foundation for synergistic mechanics in my game, so I'll start by looking at some other games' implementations of them:
    Spellbreak. Source: https://spellbreak.fandom.com/wiki/Spells_%26_Sorceries. Spellbreak prides itself on elements which interact with eachother and synergise with eachother, but actual interactions seem to be limited. Most of the synergy comes from setting up one move with another.
        Elements:
            Fire:
                Lingering Flame Puddles on ground hits
                Walls of fire causing status effects. Blocks Ice/Toxic
                Status effects deal damage over time.
            Stone:
                Must be grounded to use shockwave attacks, which travel down slopes easier. (Maybe in my case, they could travel through walls?)
                Able to throw boulders which increase damage with airtime. Deals self damage.
            Toxic:
                Toxic clouds and streams which apply status effects
                Status effect ONLY damages armour/shield, and therefore can not kill
            Lightning:
                Fires projectiles with high falloff, with consecutive shots increasing projectile speed.
                Summon lightning strikes after a short delay, damaging in a small radius (inflicting self damage)
            Ice:
                Fires projectiles which can be charged up at the cost of mobility and mana. Charging in mid-air inflicts Hover to the player, suspending them in the air. Hovering halts mana recharge and cooldowns.
                Can create freezing fields in an area around the player, inflicting different tiers of slow status effects leading to a complete freeze. The area is impenetrable by fire, wind and lightning, making it a good defensive option.
            Wind:
                Wind projectiles deflect spells
                Whirlwinds pull opponents in, and pull airborne opponents harder. Can afflict the caster.
        Immediately there are some interesting ideas to take from Spellbreak:
            Self-damage: Powerful spells are a risk to the player, meaning that they can only cast them in some situations
            Status effects: It would be interesting to have a status effect system with stacking statuses and statuses which can nullify others.
            Charging: Spells are more valuable when charged at the cost of the player's safety
            Defensive auras: Good area denial and crowd control can translate well to PvE combat, giving the player room to work and breathe.

    Magicka 2. Source: https://magicka.fandom.com/wiki/Spell_Combinations. This game has a very uniqe spell system: from the start, the player has access to 8 elements and 5 spaces in the spell queue. Adding elements to the spell queue and casting clears the queue and creates a spell which combines properties of the things in the queue, with some specific combinations yielding totally unique spells. All elements have an anti-element which nullifies the other from the spell queue, meaning that they can not be cast together. Players can self-cast, creating an area of effect around them. Players can also cast on their weapons, imbuing them with elemental damage for a short time.
        Elements:
            Shield: Cast will now encase the player in an element of their choice. Elemental shields absorb matching damage and convert it to healing
            Rock: Cast now hurls an elemental rock instead. Rock self casts create damaging rock formations.
            Life/Death: Cast is now a beam, with either added damage or healing. Beams can be combined, but if a life beam intersects a death beam, a very damaging explosion is created.
            Water: Cast becomes a spray, which has knockback and wets enemies
            Fire: Cast becomes a spray, which has high damage over time and causes enemies to panic.
            Cold: Cast becomes a spray, chills targets or freezes wet targets.
            Lightning: Cast becomes an arcing lightning stream, dealing increased damaage to armoured or wet targets
        On top of these base elements, there are element combinations which yield new ones:
            Water and fire make steam, a low damage wetting spray that enables combinations with lightning.
            Water and cold make ice, chagngning the cast to a rapid fire, piercing shard stream
            Water and death make poison, a spray-type cast which applies heavy damage over time.
        Players get a sense of mastery from rapidly adding elements to the queue based on what they need at a given time, and this is exactly the feeling that I want to give players in my game. Elemental interactions are not that distinct, but the sheer number of offensive options is enough to make up for that.

At the moment I think it'd be good to implement a very simple Rock-Paper-Scissors element structure to the game, so that interactions are assured by the x beats y beats z beats x structure, and so that the interactions are easy to understand.

I want elements capable of dealing damage over time, doing area denial, moving targets around (both for mobility and for concussive damage) and map layout manipulation. My first idea is then Fire > Ice > Water > Fire.
    Fire spells by themselves provide crowd control via area of effect and damage over time. Fire spells are also strong against ice based moves and can cause icy structures to explode into shards/steam. Fireballs melt ice along their path.
    Water spells by themselves allow for concussive damage through knocking targets into walls (similarly to Poseidon boons in Hades), and can serve as an intuitive mobilty option via self-knockback and surfing on water. Water can douse fires and block fire damage from enemies, but it can also freeze to allow for skating across ice.
    Ice spells by themselves provide simple kinetic damage and the ability to block passages for enemies via ice walls. Enemies can slip and fail to reach the player due to icy regions, and ice can further freeze and redirect water.

These elements not only have distinct strengths, weaknesses and firing styles, but they also have presence in the game world, enabling to create interesting passive effects for the player to take advantage of.
    Being on fire is undesirable, and players have to be careful while navigating around firey hazards, but passive cards could buff ignited players or reduce the negative consequences of being on fire.
    Ice could be difficult to navigate, but there could be passive cards which increase player mobility on ice, or cards which reward the player for slipping around.
    Flooded terrain would slow player movement and impede fire spells, but passive cards could automatically freeze water in a short radius around the player, or allow them to hover over it to use it as some protection against opponents. 
Coincidentally, this is the element system of the critically acclaimed and beloved Club Penguin Card-Justu minigame. I hope my work is not seen as derivative (!)

There are a lot of questions to be answered about how to balance these mechanics and about how they all fit in the structure of a run, as well as plenty of technical questions, but I will focus on implementing a barebones version of this system and then play around with what makes it fun.

I am also very interested in implemeting lightning, as it is one of the more fun elements in games like this due to its chaining capabilities. Writing visuals for it would also be very fun! If these three elements don't satisfy me, lightning will be the fourth.

In terms of how I would create the assets for all of this, I am heavily considering using very simple block, circle and line graphics in the prototyping stage and writing particle effects and shaders for the final release, which would just use those (now invisible) blocks and circles and draw over them.

29/1/24

I've gotten to a point now where I really need to work out how to implement some basic combat mechanics in a sensible way, so I wanted to read through the introductory documentation again and take some notes on what might be useful. I want to figure out how to detect projectiles striking a target and applying damage to them. It seems that I should use Area2D to define hitboxes and to act on them accordinly, but the question remains over who should be responsible for dealing damage to a target: the projectile, or the victim?

2/2/2024
Meeting notes
  Air as an additional utility element to boost fire, knock ice around, spread water 
  Limited use and unlimited use cards
  unlimited cards cycle to a discard pile
  Potentially abilities to reshuffle or redraw
  Cards imbue your dash

  Fire hurts you, but passive cards can:
    Replenish health on fire damage or casts
    Empower your fire spells
    Make you less vulnerable to other elements: totally vulnerable to one hit of water

  Extra "void/darkness" element for various utility spells like teleportation and deck switches 

  Passive cards to add more charges to dash or give normal dash effects
  One step from eden as a study of a real-time card combat system

  Prepare consent forms and things for next meeting

Note: want to switch to a f=ma based model for movement so that areas can apply forces when you are in them and so that enemies can have mass stopping them from being pushed

Development notes for ice floors:
First attempt was to completely remove friction as this is quite intuitive, but the current movement model relies on having damping to cap speed
Added a hard speed limit, but there is some undesirable behaviour when hitting walls after sliding on ice: it is difficult to turn around the character's velocity does not get zeroed on collision, it simply gets prevented.
This issue is tempting me to use a custom entity class for the player and for enemies, as opposed to the CharacterBody2D, so that I have finer control over movement, but I do lose some nice features. There is likely some utility function on CharacterBody2D to give me the information I need to rectify this stuff.

Brief tangent to try to get icy areas to add a blue tint under them via shaders, but Area2Ds refuse to render.

3/2/2024
Did a lot of thinking on how I would like the floor effects to look and function, but eventually I had to cut back on my requirements for the sake of getting a prototype working.
I wanted to define them as arbitrarilty shaped Area2Ds, but due to concerns over how to program graphics for this (how do I work out which pixels are in the area in a performant way? how do I know how far from the edges are they?) I cut back to having only circular floor effects with ColorRects over them to be able to apply shaders. I am concerned over how this will work for transparent effects (since colorrects can overlap) and how it will work for effects like fire, but I am hoping that creative shader code will save me. Or a slight refactor.

I also had a thought about how to do enemy pathfinding. For some reason I had it in my head that I had to immediately use navigation meshes, graphs and AStar, but it is far easier and more realistic (for most enemies) to use raycasts to check where enemies can go and have different wandering states for them. Also gives me room to make more creative enemy behaviours.

I will create an avoidance node that takes as input the direction that an entity would *like* to go in.
First idea: shoot two rays, left and right, and angle the suggested direction away if those rays differ in distance to collision length. There are obvious problems with this, namely that this is a greedy approach and the enemy will NEVER turn away from the player to round a corner. It's also sensible to weight how much the entity cares about the suggestion.

I can actually exactly in which direction the entity should go to be parallel to the surface that they are trying to avoid by making, since I have the points of collision - which are presumably on the same straight surface (bold assumption)

First attempt at this done, there are a lot of in-code comments on why certain decisions were made. This isn't too bad, but needs a lot of iteration. Still need to integrate this with a line of sight check, too. Also, we are not accounting for delta time, so our target direction changes quicker at higher framerates.

Circling back to the floor effects, I did some more work on the ice shader to clean it up a bit for the new system. It's better than it was, but again, not too good yet since its clear that new areas get added at discrete time steps.

4/2/24

I did some more work on yesterday's ice effects, refactoring FloorEffects a little so that I can easily attach Area2Ds to them. I've started now to understand why everything should ideally be in the scene tree and how to create useful scene components - you can always add more children and extend scripts if you want an instanced scene to have more functionality.

I added functionality to the player that multiplies their maximum velocity while sliding on ice, creating an already interesting system where you can skate on ice to drastically boost movement speed at the cost of maneuverability. It needs some more work as the immediate speed decrease when getting off ice is quite jarring. I also need to rework how the ice fades away so that its clearer which areas are icy and which are not. It would also be an idea to decrease the ice wave's area of effect as it travels, by making progressively smaller areas over its lifetime.

I realised while working on the ice wave that it might be desirable for a card to create multiple projectiles - for example an upgraded ice wave card would send multiple waves in an arc. Definetely something to look into by the prototype release.

I also added a "say" method to the player that I plan on adding to most entities that gives them a little dialogue label for a short time - this doesn't really feel right at the moment, since I would probably want the position of the labels to be totally independent of the player (so that they stay where they were created). I also probably want a handler node for them, since I don't want players to say too much and too often, or for text to overlap. This system was inspired by Crypt of the Necrodancer's dialogue.

I've decided that a fixed "max velocity" doesn't really apply to a physical system so I've decided to rely strictly on acceleration and damping to determine the player's neutral speed. There is still a maximum speed so that the player does not accelerate infinitely on ice, but it never changes (like when they would come off the ice). I had to decrease the damping of the player because I wanted them to slide more when coming down from a speed boost, but as a consequence I also had to reduce their acceleration so that they would not go too fast in a neutral state. I may have to reconsider this later, as the player is now less responsive, however sliding off ice feels "right".

Fire can now "melt" the ice on the floor by making it disasppear now, but I realise that I need to rethink the floor interactions that I wanted. Previously I wanted:
    Fire melts ice on the floor, turning it to water
    Water puts out fire on the floor, turning it to hot damaging steam
    Ice freezes water on the floor, turning it to ice
But I also wanted floor effects to have defensive properties, like water putting out fire projectiles. I may need to restrict these properties to real entities on the map (doesn't make much sense that floor water would put out flying projectiles anyways!)
It's also worth noting that while it is possible to create steam by putting out fires, it is unintuitively impossible to create steam by throwing fire at water. Suppose you can justify it as the fact that water beats fire, therefore fire should not have advantages in water.

I now realise that I need to think about what happens to the player when they die... For the prototype, I will likely reset the whole scene?

5/2/24

I had a good conversation on the Godot discord earlier about composition and inheritance - I asked how I could use the former to solve problems that I can already solve with the latter, since it seems that every game dev tutorial advises against over-using inheritance. If I want two enemies to have different attack patterns but be the same data type, typically I would have them both inherit from an Enemy class and implement their own behaviours - but I can instead have just the one enemy class with various controllers that the enemy class expects:
Enemy
    - MeleeAttackingController
    - MeleeAI
    - Sprite2D
Enemy
    - ProjectileAttackingController 
    - RangedAI
    - Sprite2D

Enemy could even be generalised to Entity, and Players could be entities with PlayerControllers instead of AI components. Certainly don't want to make a system this flexible for the prototype deadline, but it may be a good idea later down the run, to handle various elemental effects - and multiplayer, and giving enemies player abilities to scale difficulty!

I can have one primary enemy scene which contains almost exactly the same code every time, and build up enemies from their core "components". I think this is the conclusion to the resource systems that I was trying to work out a couple of weeks ago. Time to rewrite the enemy class!

First of all I want to refine the avoidance system since it just didn't work very well last time - the rules weren't exhaustive or sensible and there was a very if; else if; else if ... approach to the problem. I want to have a node which casts rays all around and can tell its parent which way is most likely to be clear so that enemies using this system.
How do I do this? Firstly, my Avoidance Vision node will contain raycasts of length 10 in each direction (length 10 instead of 1 so that I can see them better in the editor). I can then get these raycasts in an array by getting the children of the node, and then I want to do a weighted sum of their vectors in some way. I want this result to represent which direction is open, so weights should be higher for directions that have no obstacles in them: my first idea is then to sum across direction * ray_cast_collision_distance / ray_cast_length. I can scale ray cast length by some amount using an export variable, and use it to control how sensitive the enemy is to its surroundings.

First result: Combining this sum with the enemy's preferred direction (towards the player), they do a reasonably good job of getting to the player while avoiding walls - there are some issues though:
    Enemies tend to crowd around eachother since they all want to stay central to the rooms. This can be fixed by making the raycasts collide with enemies too, though
    If the enemy is in a horizontal hallway above the player, the sum directs them upwards but not to the sides, so in some cases they won't pick a direction to go in. Not a huge deal, since this seems unlikely, but I will have to keep an eye on this.
    The enemy is still dumb and will not circle walls perpendicular to where it wants to go. I may have to reimplement the old system of carrying over some of the last turn's movement into the next one.

https://youtu.be/8uE6-vIi1rQ
I watched a GDC talk on "Cursed Problems" in game design and it reminded me that I need to evaluate my own game's "player promises" and how I can both make sure they are met and that they don't conflict too heavily. Here is what I am seeking to provide the player: 
    An experience with lots of things to keep track of at any given time and some randomness is involved
    An experience where the player constantly feels at their limit - you MUST use everything in your arsenal and more to progress\
    An experience which gets the player feeling accomplished via skillful play
    An experience that is persistently fair - at no point will the game present a challenge that you can't realistically manage
    A goal of building a powerful character that is distinct in each run. Their power is measured by their score and/or stages cleared
    The ability to build characters in certain ways - there is some player choice involved
There don't seem to be any immediate outright conflicts, but it is very hard to balance difficulty to meet all of these points at all times, so some may have to be relaxed, as suggested by the framework in the talk. Skillful play and chaos will be difficult to balance. Although I am targeting this game at people that have played similar games before, it is no reason to not cater to a wide range of skill levels - players which are not competent initially may grow to enjoy the game much more later. 

I have some ideas about how to scale the game around the player, but its not clear if any of these will even apply to my game after the prototyping stage:
The player's score can be used directly by the level generator to assess how many enemies to spawn. Therefore, the score should scale linearly with the player's power level. Maybe this can be accomplished by having score be dictated by the number of cards picked up, but this is unintuitively as some cards will increase the player's power multiplicatively (or worse!).
There could be a separate score maintaned, the "equipment" score. This could be an estimate of the player's damage per second, or other offensive/defensive attributes, and could be used to ensure that every room will take approximately the same amount of time/casts/gear to clear. Each item picked up could contribute directly to the equipment score.
It may also be worth using the player's level clear speed to scale difficulty, to provide an experience which rewards players for playing well and fast - embracing the chaos.
A higher score may reward the player with more gear to provide a real incentive to play well - I could reframe score as "magic power" or something like that, to indicate that it shouldn't be disregarded like any other score. If the player gets to the final boss quickly, they will be a fair bit more powerful and have more destructive abilities, but I have to take care to not scale the final boss encounter too much, or all this effort will be wasted.
A system which scales difficulty with speed may end up doing the opposite of what is intended, causing players to play slow so that they get a more manageable final boss, if that is the win condition. Very tricky, requires more thought, but I wanted to get ideas down now.

Back to the raycasting for enemy AI, I think this system needs a rework. The avoidance node reports which direction is clearest, but enemies will weight it all the same even if they aren't really in an enclosed space - I'm going to rework it so that the output direction is not strictly 1 long - it can be anywhere from length 0 to 1 depending on how much influence it should have. To do this I need to normalize less aggressively.

This still does not solve the problem that I sought to solve, which is that enemies would refuse to bend around perpendicular walls to get to the player. I think some notion of state of a line of sight, or perhaps an "exploring" state might help to solve this problem. Either way I think its time to rework the enemy class to be more component-oriented.
So what can enemies do?
    They can have certain movement AIs, so they should have an AI component
    They can have different attack patterns, so they should have different attack controllers
    They can have different attacks, so they should have different Weapon Components
So an enemy should then have a movement controller, an attack controller and a weapon.
The enemy's movement controller determines where the enemy goes, and the attack controller should dictate when it attacks. Weapons are used for those attacks, which will spawn various effects on the stage and deal damage to the player. The enemy scene should mediate all of this.
But on second thought, weapons are critical to attack behaviour due to their range, so they should instead be components of attack controller - which will read information from them and act on it. It can be further argued that movement is critical to attacking too, but I will just keep it to this structure for now and see how it goes.

After  a little bit of writing, I realise that I can actually simplify the pattern a little bit. If a component knows what its parent is, then it can access an API of the parent's quite easily, without the parent needing to provide specific information to the component. This breaks Godot's soft rule of parents being responsible for children, but it will result in much faster prototyping when I don't know exactly what information a component is going to need. Later on, I can do it the "proper" loosely coupled way, where I connect signals between the component and parent. 

I am going to make AI controllers the brain of the enemy, meaning that they make all decisions and use an API to tell the enemy what to do. 
Attack controllers will check in on the enemy's state and attack accordingly whenever they want. AI controllers can ask their parents for data from attack controllers and adjust their goals accordingly.

Here's the current layout of enemy after these tweaks:
Enemy
    AI Controller
    Attack Controller
    Health Bar
    Sprite 
    Collision Shape 
    Light
    Hitbox
    Detection circle

To make actually compelling AI controllers, I am going to start using the state chart extension. Time to learn...

At the moment I'm toying with the idle state for the enemies, and I want them to wait a random amount of time and then go to a position near them on the map. I think I might need to have a go_to(pos) method as part of my enemy API though, since this avoidance stuff is getting very cumbersome. An AI component will simply tell its enemy where to go and the enemy will find its way there efficiently. Time to learn...

Seems like the navigation system is fairly straightforward when using only navigation meshes and a navigation agent, but navigation meshes are going to be a little bit difficult to generate. Typically you could use a navigation mesh generated by a tilemap, but in my case I have two separate tile maps since I wanted ALL of the tiles from one to be impermeable and all of the others to be permeable. It might be time to look into generating my own levels so that I can generate navigation data alongside them. Or... I could rework my system to be the "intended" way, where I use different tilemap layers instead of different tilemaps altogether. Should probably do that one for now.

7/2/24

And now I realise that I can't just have navigation meshes made like that - I can definetely define an area for navigation for floor tiles, but it there are impermeable tiles on layers above, there's no way that I know of to subtract from those areas.

Video here may have some fix for this
https://youtu.be/uzqRjEoBcTI

For now I will change my walls to be whole blocks instead, and simply not place floor under them. Much better for a prototype!

Aaaaand the enemies have proper pathfinding. This ended up working incredibly well with the avoidance system that I made, fixing most of its problems, as long as I use a detection radius only barely larger than the entity, since I'm not sure the scaling with distance works as intended.
I am going to have to go back and rework the navigation meshes later, or generate them as I make my levels (which is much more likely), but the system should still work exactly the same.

Now to write enemy behaviour: since I want enemies to have a go_to method, I need to detach navigation and avoidance from the AI controller and encapsulate it in a component for the enemy instead, which the enemy parent class can use when asked to go somewhere.

Now that I am writing an API with which the controllers can interact with the enemy, I'd really like to start refactoring things to have a base entity class, so I can have type-safe processing of hitboxes and fields of view and things like that. I have to abstain myself and make things just work.

With simple enemy states and pathfinding done, its time to work on attack controllers and finally implement a fail-state for the game. Going to have to rework my projectiles to have allegiance and have collision with eachother, but first I want to assess my systems at the moment.
Enemy AI components currently decide where the enemy should go based on the AI state, but the state is only really affected by whether or not the enemy has completed its go_to task. I'd like for the AI to be responsive to enemies being hit, or dealing damage, or slipping on ice or anything of the sort. To do this I am likely going to have to use signals emitted by enemies when their standard implementation functions are called (such as hit or move)

Onto attacks: I am only going to be implementing projectile style attacks for now, so I will want to give these enemies their own projectile-inheriting scene to shoot within their weapons.
A weapon should encapsulate shooting behaviour: how many projectiles, at what intervals, in which directions, as well as a cooldown. They should also report a weapon range, which can be extrapolated from the underlying projectile's velocity and lifetime. 

Attack controller
    has Weapon
        has and instantiates Projectile

I want to design this system in such a way that attack controllers can lead their shots for ranged weapons: so the controllers would to get detailed projectile information from weapons - or, perhaps for better encapsulation, weapons report whether or not they could hit a target at the velocity they're currently moving.

I've decided to structure things such that weapons are most of the code involved in making weapons work, handling projectile instantiation and leading shots and aiming and things like that. Weapons have a use function which takes user and target position, and the weapon handles the rest. The only parameter for the weapon base class would the projectile they fire.Different weapons can therefore vary in fire pattern, shot leading, cooldowns, secondary effects, etc.

At this point I'm not entirely sure what purpose the attack controllers would serve, but I am going to keep them in regardless since they are a lightweight wrapper and I may come up with other things later.

Funniest bug I've ever seen. Forgot to add projectile allegiance.

While I was doing work around the house I watched
Custom Resources by Pefeper
https://youtu.be/vzRZjM9MTGw?si=do8BCwlL-wffOClB
And it made resources and data-driven development click a little bit more. Specifically, there was a part of the video that showed him creating a list of various death effect functions that were run by actors in a 3d game whenever they died - this is potentially a pattern I can apply to on-hit and on-death effects, and maybe even passive cards and the like. Definetely need to look into data-driven game development properly.

8/2/24

https://youtu.be/U03XXzcThGU
This talk by the co-creator of Caves of Qud had some pretty scary but quite ground breaking programming patterns in it, and it also happens to reference quite a few resources with more details on data driven patterns like it.
It's honestly quite a scary watch for how different the programming is to make an effective scaleable roguelike, but I will turn to my prototype for now and worry about making it data driven after a few more iterations! There is much more research and exprimentation to do, but the end goal is data-driven for sure.

https://gameprogrammingpatterns.com/
This website has also come to my attention today, and I will absolutely be using it as a resource from now - it's pretty much exactly what I needed.
    Command: Could be generally useful for movement controllers, but I don't know what sort of structure I'd want those commands to have...
    Flyweight: Would already be in use if I would implement projectiles with resources again! Very useful, very good to remember.
    Observer: This is just signals! Very critical. One comment made in the book is that generally the parameters that would go along signals are the emitting object as well as a generic multi-purpose data object, potentially an enum or a child class of an Event.
    Prototype: A class which generates clones of an underlying prototypical object, copying all state using a provided cloning method. Potentially useful for things such as spawners of different things. To avoid having to write cloning functions though, we can also just give spawners constructors for what we want to spawn.
    Singleton: This whole section just demostrated that I really don't need a floor_effect_handler, I was just not wanting to add floor effects to the main screen tree, for some reason? Lol.
    State: Already pretty familliar with FSMs. Good to remember that they can be useful whenever you have lots of complex branching based on mutable state. Without using heavyweight FSM structures, you can already simplify code by having your states be in and enum and switching them.


9/2/24

Refactor time!!! Yipee!!!
It's clear to me that I should at least *experiment* with the principles I've learned, even if I don't want too and even if it doesn't accelerate development towards the prototype. I don't have enough time to develop systems that aren't even close to what I'll need in the future, and if progress today is promising I may even end up in a better position than I was before. Fingers crossed.

Let's then talk about entities. First of all, I need to choose what node they will inherit from - since I don't want to make projectiles entities too, since it would make my job of refactoring a lot harder, I am going to make them inherit from CharacterBody2Ds.

Now, entities might have a few different ways of interacting with the world:
    They can have active hitboxes
    They can have hurtboxes and be hittable by other entities or projectiles
    They can have different collision properties
    They can have different physics parameters
    They can have different movement patterns, controlled by either AI or input
    They can be visually distinct

If I wanted to turn any of these into components, the data that these components would need are both the self and sometimes the entity which is interacting with them. 
To help thinking of an implementation and how to connect all of these separate components, I am going to think about a concrete example: the player.
The player entity by itself will do almost nothing. First I'll define a graphics component which will handle the player's sprite. I'm already not sure what sort of interactions I would even want this component to have with the entity and other componenets, so I'm going to look into data-driven games dev a little more.

Sources for research spree:

https://www.computer.org/csdl/magazine/co/2022/05/09771161/1DeEYnefsoU
The Data-Oriented Design Process for Game Development


https://www.youtube.com/watch?v=JxI3Eu5DPwE
by the author of
https://gameprogrammingpatterns.com/
Cool AI Concepts: Fear, fleeing, flow by scent
Inheritance works better for shallow but broad inheritance trees
Using components to represent capabilities instead of domains
Domains being physics, ai, sound, graphics etc.
Every Goblin monster has a breed as its component - there is only one instance of their breed (Type Object pattern / Godot Resources)
    Each instance of a class is basically a separate type here
Abusing the command pattern (in this talk referred to as Actions)
    When in doubt, try turning an operation into an object that you can run. Take some verb and make it a noun.



https://docs.godotengine.org/en/stable/about/faq.html#why-does-godot-not-force-users-to-implement-dod-data-oriented-design

https://www.gdquest.com/tutorial/godot/design-patterns/entity-component-system/

https://www.youtube.com/watch?v=jV-DZqdKlnE

https://github.com/mxgmn/WaveFunctionCollapse

https://www.youtube.com/watch?v=4uxN5GqXcaA

https://godotengine.org/article/why-isnt-godot-ecs-based-game-engine/
This article, as well as GDQuest, recommends https://github.com/GodotECS/godex

https://www.reddit.com/r/roguelikedev/comments/7luzxx/items_in_roguelikes/
One user suggests coding items as having a list of effects! Very nice.

Back to Game Programming Patterns:
    Subclass sandbox: Subclasses use parent protected functions to define their own behaviour

10/2/24
Today I'm going to try implement an adapted version of what I've seen with with Component based systems and Caves of Qud.
An entity has a distribute_signal method which takes an entity and an event to distribute to its components. It sends this event to each of its nodes in sequence via their recieve_signal method, where they will switch based on the event type given (hit, taken_damage, moved, etc.) Components can completely ignore the event.
To extend this based on Qud, I will be allowing each child return either the modified event or null, so that children at the top of the node hierarchy can consume or mutate events. I am not totally sure if this is quite as useful as Qud's system, nor do I know what I will use it for, but it is an inexpensive addition to the system.

Components in these systems often describe what Entities can do, so what can they do?
    Collide - so we need a physics component
        Physics component is mostly handled by CharacterBody2D, but this is already a problem: I am relying on the children of my entity all being components, while CharacterBodies expect a CollisionShape2D as a child. I've had decision paralysis for a few days now, so I will drop character bodies and attempt to implement my own solution. My solution will take movement signals emitted by the brain of the entity and act on them.
    Have an appearance and change animation - graphics component
    Be hit - Have a hurtbox component
    Deal contact damage, maybe - Have a hitbox component
    Own items - Have an inventory component
    See other entities - have a detection field component
    Move - Have a brain component, which can be AI or input capture
        This will simply emit movement or interaction commands to the entity.

I will work on collision and movement first, and simply have a barebones graphics component for debugging.

Forget it! I don't need to extend the physics system, surely. I will make my entities inherit from CharacterBody2D and work on those assumptions. Physics components will encapsulate how characterbodies move, if that. I've tried to think of ways to implement my own collision with raycasts and areas but its simply not worth it.

12/2/24

Haven't been able to do anything for the last couple of days due to circumstances, so back on development now.

First thing to do was to work out why the characters are suddenly jittering, but I went to older versions of the project and decoupled the camera and ran into the same issues - apparently Godot 4 does not play well with pixel perfect scaling, but there are workarounds. I will have to investigate them later, though.

Putting all this aside, I'd like to work on hitboxes and hurtboxes next.
I can make EntityComponents which contain and manage an Area2D.
Or rather, I can assume that all children of these components will be Area2Ds and act on them accordingly, so that I can define hurtboxes in the scene editor per-entity, but I have to give some thought into how attacking will work first.
I have the option of making everything an "entity" or "actor" so that projectiles can have hitboxes that act on hurtboxes, and although this complicates things in the short term it will be good to have the flexibility later on.

Suppose we have a fireball projectile that can damage opponents and is destructible - it has a hitbox and a hurtbox.
If we want to make use of Godot's collision system, we must use Area2Ds and the signals which they emit - the "area entered signal" is most useful. Hurtbox or hitbox areas could theoretically both be looking for collisions with eachother. Since entities can have various resistances to damage, I would like to have the hit-ee be aware of the collision rather than the hit-er. This way it can query the attributes of the projectile's hitbox component and apply defense calculations, and if need be report to the projectile that it has hit something. 

With all this considered, a hitbox must know how much damage to do and a hurtbox must know how much damage to take.

14/2/24

Naturally after all this messing around with pixel perfect camera settings, the problem seems to be completely nonexistent on linux. ??????
I am going to steer slightly off course from the hitbox/hurtbox development and work on generic components for my entities, today, which don't need to consider projectiles as well - although I think it would be a good idea to make my projectiles entities as well, and potentially my chests too - it will be easiest to add various effects for. I can for example have a linear projectile "AI", or one which allows for bounces on collision.

At the moment the big question is how I can decouple animations from everything - I need an animation system which can rely solely on my events to decide which animation should play and when. I'm going to have a study of the more complicated animation nodes in Godot, like AnimationPlayer and AnimationTree.
It looks like these nodes are more appropriate for complicated state systems, but realistically most of my entites will have three animations - idle, move and attack - perhaps even a hurt animation. All of this can be handled by a component reading events and wrapping around an AnimatedSprite2D. For bosses, which might have more complex behaviour, I can create generic events so that a custom AI and custom animation controller can communicate with eachother without affecting the functionality of other entities.

All of this sort of makes me feel like I am neglecting Godot's signal system, but I'm not entirely sure how to achieve this sort of thing using signals.

16/2/24

Continuing with creating entity components to regain previous features:
    Make things animated
    Make player shoot
    Make player dash
    Make enemies shoot (differently?)
    Make entities die
    Handle player death
    Have inventory infrastructure
    Have various bars and things

I've made things animated now, and I've decided to work on inventories next since I do want to see how most of the other parts will slot around then and whether or not I'd have to redesign some things. I am going to make inventories a critical component of entities, making them necessary for entities to attack at all. I will model the system such that an AI controller can send an "attack" event and the inventory will use whatever item it has it in that can count as an attack.

Inventories will contain nodes which serve as items and items will contain nodes which serve as actions.
Actions can include things such as:
    Inflict stat changes or status effects on the user (by sending them events)
    Create projectiles (or, as a consequence of the entity system, any entity)

I am wondering which types of events an inventory might need to know about. The main thing I want inventories to respond to is "use" commands, which require context about the direction in which to use, in case the item to be used is a projectile weapon. This kind of complicates things.
I want spells to have many different aiming styles, and I want to support mouse and keyboard and controller equally well. Some spells will simply shoot a projectile in a direction, which is simple enough, but some spells may lock on to a target and "spawn" on them, or steer towards them. 
I am going to make it the item, action or projectile's responsibility to define these behaviours - to keep things super simple on the input end, the only parameter to the use command will be a direciton, which translates well to both input methods and lets the item act on further logic. If an item knows which direction it is to be used in, it can find a target in that direction with a shape or ray cast. 

For probably the third or fourth time, how is getting hit going to work? Hitbox component areas are going to respond to collisions with hurtbox component areas, and will distribute a "hitbox contact" event to their entity. This damage dealt event passes through pretty much every component of the parent entity so that various things can happen for the damage to be dealt. Once the entity has allowed all of its components to act on this event, it will pass it on as a "taken damage" event to the hit entity.
This damage event passes through every component of the hit entity, allowing it to be transformed based on defensive attributes or ignored due to immunity, and after all components act on it the entity will take the damage.

Contact events may need to be modified by componenents which act on damage, damage type, penetration, and status afflicion. Hit events will go through defensive items in inventories and go on to potentially deal status afflictions as well. This would be a good time to think on a system for this.
Status afflicions might include things like fire tick damage, elemental or plain weakness (which can also affect damage taken), attack buffs, etc.
I was thinking of making the inventory store passive cards as well, which will modify offensive and defensive events before they get processed, but it doesn't make sense to mix items that can be used and items that give effects.
I was also thinking of having entities which are immune to different afflictions or entities which are permanently afflicted by them.
A separate inventory of cards which denote passive effects might then make sense, and these cards could individually alter events, same as components. Cards can manage their own lifetimes so that they expire after a certain amount of time or under certain conditions, and cards can even signify status effects. 

I realised that I forgot to account for something - projectiles created by the player may have different on-hit or on-death effects based on the player's passive cards, and may inflict different types of damage as well.
When the inventory instantiates a projectile, it will fire an event to say that it has created a projectile that should be fired. This event contains the projectile to be created, so that it can be altered as it passes through components that will affect its stats.

17/2/24

Hurtboxes and hitboxes need to have some concept of a "team", and this concept needs to change as they move, as I want spells to be able to deal damage to their caster, but not in all cases and not as soon as the spell is cast. The components of the entity should be able to change its team as the lifetime of the entity progresses - so that a fireball that is cast will be able to change its team to "any" when it progresses far enough away from the player. Although this seems like a sound fix, I am still worried that an enemy casting a spell into another enemy that is very close to them will not be affected by the spell, and this could be quite noticeable.
Instead, when a spell entity is created, it should only ignore its creator for a short period of time, rather than any entity on that team. This should cover most cases. The concept of creationship will not apply to every entity.

Here's a new concern: I now have three different collision areas on my entities - one for world collisions, one for hitting things, and one for getting hit. Some entities need to disappear when colliding with a surface, and those surfaces might be other entities. How do I make it so that they don't get deleted before they have a chance to touch whatever they hit with their hitbox?
    I could make projectiles not collide with other entities - after all, I only need this functionality so that entities don't step over eachother.
    I could make projectiles use their hitbox for their destruction instead of their collision box - but there is no assurance that the thing they hit even has a hurtbox, so interactions with things like the tilemap might need special considerations. Hitboxes should only interact with hurtboxes. 
First option doesn't immediately seem to have big drawbacks, and any I can think of seem to have workarounds.

So far I am pretty happy with the way the component is coming together, as I can think of a few different ways to implement projectile-specific components that slot in with my system. For now, I can have graphics be handled by a sprite2d, but later on I could have shader-driven components that can respond to movement and hit events to change their appearance. Using characterbodies for my entities also enables more sophisticated behaviours on collision, like sliding along surfaces and detecting collision locations.

18/2/24

I believe I finally have a working system for taking and dealing damage: it comprises of two components, four events and one DamageData type.
    The two components, hitboxes and hurtboxes, expect area2Ds as children for collision detection. Hurtboxes do nothing (for now), and hitboxes have a DamageData parameter and will send an event with the data attached when they detect a hurtbox.
    The first event to be sent is a HasHitEvent. The event passes through entity components so that the damage data can be modified for damage buffs and effects, and once it makes it through the entity, the entity will let the target know that it has been hit with a BeenHit event. This event makes it through the target entity to have resistances applied to it, and finally the target distributes two events:
        TakeDamage is distrbuted on itself so that stats, behaviour and graphics can be updated.
        DealtDamage is distributed back to the aggressor so that it can now how much damage was actually dealt and gain on-hit effects, for example.

Absolutely perplexing issue with what I thought to be pixel-related jittering - entities alternate between two different positions when in motion, UNLESS there are multiple angels in the game. Then they behave fine. What in the world???

19/2/24

Today I have another supervisor meeting, so I've started with cleaning up all my files after the big refactor of the last few days. Not sure what meaningful features I can implement before the meeting, especially since I also need to have another look at the ethics information. 

Things to discuss:
    Digital signing of ethics forms
    Anonymisation - when is it approriate to redact names
    Linking participants together between separate beta tests
    Information on the consent form
    Previous build of the game
    New build of the game
    Pixel perfection and the "fix"
    New structure of the game

Meeting notes:
    Agents may be calling a redraw during the game only every once in a while?
    Focus testing and or focus groups
    Screenshake + additional juice
    Polygons added to existing floor effect meshes'
    Distance functions for polygons might exist?
        PackedVectorArrays and Geometry2D
        Or just passing vector arrays for polygons staright to the shader for finding SDFs!!
    Convex hulls for joining shapes

20/2/24

Following yesteday's meeting, I have a few new short term objectives:
    Now that my refactor is complete, I can start to implement the absolute core mechanics that will make up my game:
        Elemental damage and projectiles for three elements. Water for high knockback.
        Ice for slowing/freezing. 
        Fire for explosives and damage over time. 
        Basic ranged and melee-ish enemies
    To help get more useful data from my first round of testing, I was encouraged to add some more juice to the project, as it would make people less likely to dismiss the game on the grounds of it not being visually or aurally uniteresting
    I am also going to prepare materials to conduct the first study, which will serve more as an opportunity to guage interest and get feedback on ideas for future developments.

I am going to spend the next 3-4 days implementing core features for the game, and then spend a couple of days on SFX and VFX. Between the 27th and 1st, I will be conducting surveys on 3-5 friends.

First things first, I want to iterate on my damage and physics handling code.
Damage Data will have attached to it elemental type and status effects to be inflicted, which will be processed by a damage proccessing component that can determine which debuffs to apply to the to the entity. 
Status effects, in Caves of Qud fashion, will be event-altering code that is attached to a component on the entity - the damage processing component will consume the damagedata and distrbute damagetaken events and statuseffectgained events for the status effect component to take in. Since I want status effects to act on physics and movement, I will also want to create components to handle them instead of handling them directly on the entity class.

So what should status effects be able to change?
    A fire status effect should continuously emit damage events to the parent, to signify fire damage 
    Frozen status effects should consume movement events
    Water status effects may affect the damage taken from hit events, and when enemies are blasted by water they should have their movement locked for a short while so they can take kinetic damage.
    Confusion effects might be reverse movement commands or randomize firing directions.
    Speed buffs and debuffs may increase or decrease acceleration and/or damping.
    
The biggest thing to think about is how input events result in movement, and how I can make the events involved easy to alter. Input components will only tell the entity in which direction we wish to move, so these input events could come with a multiplier attached to them to determine acceleration, and perhaps a flag to lock movement completely. These move events pass through the entity and get turned to a kinematic event that is handled by the physics component to actually move the character. 

I am currently working on having fireballs explode when the despawn, by spawning a new explosion entity. I made a DeathEffectComponent to perform DeathEffects when it recieves a death signal, but I feel as if this new DeathEffect class is incredibly similar to ItemAction, and the yet-to-be-implemented on-hit and on-kill effects. May be worth attemting to unify or subclass them! I will have to work out what data all of these effects require as parameters and how else they may be able to get them. Death, kill, hit and item effects all require a relevant entity or two, so that might be a good start.

21/2/24

Onto improving actions: what can they do and what do they need?
    On-hit actions: Who was hit, and who hit them? Entities created by another entity should generally inherit all of the on-hit actions of their parent. Tied to damage dealt events
    On get hit actions: Who got hit, and who was the hitter? These actions may want to know the hitter for revenge mechanics. Tied to damage taken events.
    On-death actions: Who killed them, and who was killed? Again, these actions may involve revenge mechanics or buffs to the killer as a reward for the kill. Tied to death events.
    On-kill actions: Kinda the same as on-death actions, but they affect the killer instead of the victim.
    Inventory item actions: Who used the item, and in which direction? This is the only outlier for all of these, as it doesn't really have a target, but one can be inferred by the item. Direction can be inferred from caster and target for all the other events, too. 
    
The parent contexts of these actions (e.g. inventories or effect containers) can inject data into them on "do", so actions can all be the same type in all these contexts. 

So all actions will take one entity as a mandatory parameter, which is the caster, a secondary entity and direction as optionals - actions are responsible for checking for default values, and they are allowed to infer them - for example an item use may not have an explicit target, but it can try to find one based on direction, or it might need none of this information. 

I've now unified actions and have added knockback to damage types, which the entity scripts handles for now, but I would like to extend this in two ways:
    Knockback should be a modifiable event such that inventory items can prevent it - this is already pretty much implemented as the damagedata passes through components and the knockback value is mutable, so on second thought I won't bother.
    High velocity collisions into walls should inflict splat damage. This damage needs to be tied to the correct entity so that on kill and on hit effects can be computed. 

Since knowing who is responsible for a knock into a wall is not viable, I will make the entities remember who knocked them back last and when. If knockback was recent enough, events are distributed.

22/2/24

I've been trying to fix the scuffed knockback system, and it brought out some questions about my approach to entity ownership and entities attached to events. Since knockback damage will often happen after a projectile despawns, the knocked back entity has no idea which entity last knocked it back - it needs to know this for the sake of on-hit, on-death, on-kill events and the like, as well as potentially for general kill atrribution for stats.
At the moment, entities that are owned by another entity are still responsible for dealing their own damage, so despawning them leads to a use-after-free or null error.
It would probably make sense for all owned entities to report damage back to their owner, as the owner is much less likely to despawn, and if they're dead, it doesn't really matter if they have on-hit or on-kill effects. 
However, if an owned projectile outlives its parent, we still end up with a problem - it can't send damage dealing events to its owner. 

And yet another issue: suppose the player has a "projectiles explode on hit" card and fire a projectile which they obviously own. This projectile hits something, and because of the card it will spawn a new entity that is owned by the player and should therefore also explode on hit, cascading and killing an enemy instantly.

At this point it makes more sense to attach all the required information to the projectile when it is created - although this may be wasteful, it is simple and structurally sound. A projectile, when created, has its behaviours defined by its owner and then stops caring about whether or not the owner is alive. 
This still has an issue, which is effects such as "heal on hit", but they can be hopefully solved with a check for null. A "heal-on-hit" action would also need to either only ever try to heal an owner or the parent entity.

I will introduce a "created projectile" event to help in fixing this problem, so that projectile behaviours can be injected by the inventory of the player after the projectile is fired. This way, projectiles do not need owners at all - their owner can be defined by injected behaviour.

I need to make two compromises: TakeDamageEvents are no longer tied to a dealer, since they may be despawned and are not too relevant anyways, and I can no longer have projectiles not hit their creator specifically - I will simply start using the team enum declared on entities, and have components that change this enum when needed, like after a certain period or on explosion.

And of course now I realise that the immunity frame system I built relies on hurtboxes knowing who hit them. I am going to have to make it the hitboxes responsibility instead, to track which entities to not hit again, which is honestly easier anyways.

23/2/24

Having done all that, it's back to adding first release features. I want to add an Ice projectile which either inflicts freeze, or creates ice patches, both of which would require new mechanics. Additionally, both mechanics would want to modify movement events inbetween input and addition to velocity, so I should decouple physics from the entity component.

Controllers will emit input events which will pass through components and then be redistributed as "attempt move" events, after which they will finally be processed and a true move event will carry this data to inform components.
The question remains of how I would like to handle ice changing movement attributes. If components signify what an entity can do, then a component for handling grounded movement can alter the damping and acceleration tied to an attempted move event, but damping needs to be handled per-frame, not just when there are input. 
A component which processes whether or not the player is on ice and mutates a move event will only check for ice when that event is fired, but movement is continuous regardless. 

All this considered, it may be better to have the entity class or a physics handling component do all of the computation and checks required - it could eventually send events through the entity to poll what movement parameters are affecting the entity. This component will simply move its parent and distribute collision events.

I am beginning to work on detection of whether or not we are in ice fields, and I wanted to save a link in case it would be useful for shading later:
https://www.reddit.com/r/godot/comments/ctz3rk/comment/exvfx6f/
"Shader language - Applying a shader based on if a pixel is in a polygon2D."

Now that ice effects are affecting physics correctly, I need to make them appear and disappear from the floor.
I am opting to have a global autoload singleton which will expose functions for entity components to interact with. Components can add floor effects for a specified duration, or remove them from a specified area.

A lot of different issues can arise from being able to remove specific areas of floor effects, since different parts of surrounding areas may have totally different lifetimes. Although it is possible to maintain an array of original polygons that make up our new polygons, operations on the floor areas may become too expensive and complicated - plus, it doesn't really make sense that floor effects should have this lifetime memory for multiple areas.

Instead of this system, I am going to try make it so that floor effects decay in radius over time. This is more physically accurate and easy to understand from just looking at the floor, rather than remembering which projectiles with which attributes were fired. Additionally, this makes it so that removing parts of floor effects is trivial and does not regard how the effect was created.

I was thinking that a custom erosion mechanism might be needed, but Geometry2D.offset_polygon magically seems to do what I want - requires testing.

After testing, its clear that offset_polygon is no good - even being done only once every second, it causes noticeable stutters, and this is ignoring the performance cost of instantiating collision shapes for split polygons. I considered threading this, but it would complicate the polygon addition process - by the time the work is done, the polygon may have needed to change shape.

I tried to optimize this using convex hulls and merges, but it is not behaving as expected. Will return to it another time.

24/2/24

Ideas for floor effects:
    Grid-based custom solution, maybe using cellular automatically
    Passing in polygon data using a texture
    Falling back to storing individual collision and handling them manually in the floor effect handler.
    Enlisting C# to provide performant geometry at a low cost

I tried to experiment with using a 2D array to represent a higher resolution version of the tilemap floor. A naive implementation of adding icy areas to this array, as well as an equivalent Image and ImageTexture, only takes 40ms for a 10-radius area being added! Performance is quite promising, even without C#, and the best part is that my array can be of floats and my textures can use an entire channel to denote lifetime - passing important data to the GPU should be quite easy! Best part is that for decay, I can make it as expensive as I want - I can choose to decay only x number of pixels each frame.

25/2/24

Now with floor effects somewhat done, I need to focus on enemy behaviour and juicing. 
I did get some good ideas about game mechanics with this system though, to implement later: since icy floors make it much easier to deal knockback damage, it might also be fun if frozen targets had increased kinetic damage taken, so that ice and water synergise very well.

Options for juicing:
    Camera shake 
    Dash and dash effects
    Bloom?
    Sound effects 
    Particle effects for footsteps 
    Particle effects for casting
    Cooldowns and visualisations for them

Changelog for the day:
    Reworked iceballs - no more lights or sprites, and damping is enabled
    Fixed animations and added footstep particle effects
    Basic audio + reverb for distant sounds
    Fixed poor angel performance through less frequent target updates
    Added the previous enemy state machine - needs a bugfix or two

To discuss for tomorrow's meeting: possible focus group format:
    Ask questions about the player's previous experience with roguelikes, deckbuilders and top-down action games
    Ask the player what they look for in games of this genre
    Let the player run and play with the game a little bit
    After a minute or two of letting them tell me initial thoughts, I will start conversations of the following format:
        Ask the player to try a mechanic for demonstration
        Ask the player about the current implementation of the mechanic
        Explain to the player how I plan to expand that mechanic
        Ask if they have any comments on planned expansions
    Broadly ask the player what they would like to see from this game

    Interviews are only expected to last 10-15 minutes at most.

Maybe to still add before getting players to test the game:
    Camera shake
    More projectile particle effects
    Enemy attack behaviour
    Fire and water floors
    

26/2/24

Just working on some polish before the meeting: found some real gnarly effects by accidentally forgetting a -1 on the melt_ice subtraction and wrongly setting pixels to distance / radius. May be worth exploring for future effects.
Since I want fire to melt ice based on how far away it is from an ice tile, it may be interesting (but not necessarily sensible) to explore a temperature system to blend from ice to water and to steam for AOE damage. Just an idea.

For the survey, I am thinking of having a lot of questions that take the form of: From a scale of 1-10, how much does mechanic xyz interest you? 1 is "Would greatly discourage me from playing the game", 5 is "Would not affect my drive to play the game", 10 is "Would greatly encourage me to play the game."
    These sorts of questions can help me prioritise mechanics, and it would be good to compare respondents answers to these questions and their opinions on the mechanics once implemented.

While we go through questions, I will encourage the testers to try to play with the mechanics and/or crash the game.

While I have people test the game over the next week, I will focus on addressing warnings, janky implementations of existing mechanics and adding documentation to all of my code.

Notes:
    Collisions should let the other entity know theyve collided - one entity might need to take ownership of the interaction based on their ID or reference
    OR entities have pointyness and mass and handle their own collisions
    Try conservation of momentum (maybe functionality exists)

I tried tweaking the dash a little bit for this test build, as I'm not happy with it not instantly changing momentum on ice - if I dash left once on ice, I need to dash right twice to go right. I wonder if there is a solution for this, or if there even needs to be a solution - after all, a realisitic kinematic change in speed might be more intuitive and fun, albeit a little clunkier.

29/2/24

Following my first study interview, I am going to be making a few tweaks to my interview questions. The interview lasted much longer than expected, about 75 minutes while skipping over some questions, so I want to trim the number of questions and place greater emphasis on the ones that seemed to be the best conversation starters. Many questions simply could not be answered effectively with the amount of gameplay that I was presenting the the interviewee - they had nothing to go off of.
The beginning of the interview needs to have a looser structure, since I ended up doing a lot of the talking points out of order - also, some time was wasted distributing the game and the paperwork for the interview, so as part of my introduction I will get people to download a full ZIP from a hosting website and test-run the game before we start discussing it - instead of distirbuting the files one-by-one over discord and getting them to run the game before they were supposed to. I wanted to have people answer some questions before playing the game so that they could give me their opinions without context for the game, but it makes more sense to focus the conversation on my project immediately - and would probably save time.
I also need to rework the 1-9 question segment, as we decided very quickly during the first interview to drop the numbers and just discuss interest in features - it was much easier for conversation.
I am also going to be dropping the recording for the gameplay, as it adds unnecessary friction in the interview process and I realised that it could quickly lead to situations where I end up with footage of sensitive information. I will be deleting the screen recording taken in the first interview. Gameplay simply is not as useful a data point as it would've been if I had a gameplay demo.
The entirety of the "question segment" turned out to be incredibly long, with a lot of questions and answers lacking in focus - more game context is needed to share meaningful views on mechanics. I will be cutting the list of questions down to incorporate only the self-explanatory game mechanics.
A lot of the questions after this segment were also quite meaningless, since they would be based on the greater context of the game as well.

I already got some feedback on some features and issues, but I don't really want to make big changes to the game during this testing phase - the only change I will make for now is to make the game act proper - not to always stay on top and to receive inputs even when the window is not in focus - issues shown during the first interview.

3/3/24

Because I have some time to work but have not completed my interviews, I am going to work on implementing fire and water floors as well, and potentially work on refactoring the fire/ice/water shader system to support better graphics effects.
I've reworked the floor handler to store an array for each element and to encode them as RGB channels in an image and texture to pass to a shader. The values of these arrays and these shaders will represent different things and be handled quite differently - it might be quite sensible to split up these functionalities but they are simple enough to have in one place for now. 
Fire and water do not "decay" - it doesn't make sense to have them be handled the same way as ice. I would love for them to linger for a while and suddenly fade out from the edges. C# may be very useful for this later down the line, enabling easy data-driven programming by having each array store structs of state information, but for now a simple value as a timer will be enough. Structs might make life even easier since certain mixtures of elements really shouldn't exist.

4/3/24

Attempting to give fire and water different decay behaviours, I realise that I fundamentally want them to work the same way as ice, decaying from the outside in rather than randomly. I made the mistake of associating the values in my array with the visuals because of the current shader that I have, but in reality I can shade each cell however I want - so I'm going to give all three elements the same decay behaviour and make a simple shader that samples nearby areas of the texture.


MEETING Notes
    Make the data available to myself up to the viva and maybe to be in the appendix
    

6/3/24

Today I added some very basic level gen, refactoring the old "room-1" and made some tweaks to the floor handler to fix bugs and behaviours. I am probably going to want to make different level generators with many parameters, and I'll need to expand generation code to support placing items and enemies based on parameters as well.

8/3/24

I worked on iterating over the shaders for the graphics and floor effects because I hated looking at them. I realised that the screen-wide dithering shader was actually broken for the testing build, which is really something that I should have spotted earlier.
I figured out an easy way of getting fragment world-space coordinates in my shaders, which fixed a lot of issues that I encountered trying to write shaders before. Using these coordinates, I came up with a decent way of getting water using scrolling noise textures - I even tried overriding the light function to make the peaks of the waves reflect light better. The water is three-tone, putting aside any dithering effects.
I still have no idea how I am going to make the fire glow, considering light functions and pointlights, but I at least have some idea of how I'm going to create it graphically. Ice is probably going to be easiest of them all, but I do want to write an edge distance function analog soon. After writing a fire shader, I am going to go straight to developing items and enemies, and having them get generated within the level.

Tried very hard to implement lighting for fire by using a PointLight2D and updating its texture to match a blurred version of the fire generated by the shader, but this was not very fruitful. Godot does not support using PointLights in this way, due to optimizations. Its also not the easiest to extract data out of a shader program.

While testing on a smaller level to be able to debug the textures better, I realised that decay rate needs to scale with the area of the level, so I quickly made that tweak - this does affect performance on larger levels, but is necessary. A lot of the shader effects also need to scale with level size, so I am going to have to look into that at some point as well. Another time!

11/3/24

I've now implemented an item pickup system and some different spell types to test my systems a bit, and next up I want to implement the build-enabling mechanics:
    Passive items which have an effect on damage taken and the offensive abilities of projectiles fired. They should also react on kills and hits.
    Status effects which can affect pretty much everything about a given entity and can be dealt in various ways

Before the big ECS refactor, I was thinking of having entities maintain a list of on-hit and on-death effects that they can run through when things happen, but I've unlocked a much more unrestricted system since ANY part of an entity can react to these events. 

First thing I need to do is give entities a container for these effects - a PassiveInventory, and then I can add Effect objects to this inventory that can change their state on each frame and react to events from the entity - the passive inventory just passes these events on to them and manages the effects.

Some of these effects will be timed - these would be status effects. Other effects will be persistent, and won't tick down each frame. Both types of effects can free themselves when they are no longer needed, and they all will have associated "cards" in the UI, even if temporary.

I might want to talk about how tempermental Godot is when it comes to static analysis, compilation and the type system. I had to deal with a bug where I wasn't able to cast to a type because the definition of that type had an error in it, regarding undefined variables. No error was reported though, and everything seemed okay! There have been other times where I had to reload the project to allow Godot to compile because it hadn't registered a type name change or some definition.

I am trying to design a more complicated action to test my system - one which fires projectiles slowly in a circle around the player. Initially I thought this would be difficult as items use actions in one call, but being part of the scene tree, actions can use the process loop. This does have the "limitation" that an action needs to decide what it should do if called again during its operation. 
Options:
    Maintain multiple operations internally - quite clunky but straightforward
    Report a cooldown to the item - kinda situational, not very intuitive as items can have multiple actions
    Create an entity (though maybe a plainer object) to handle its operation separately - probably the best, and can be used as an alternative to the first option depending on the item.

For example the radial fire might want to restart when recast, or emit multiple jets up to a limit, or create an actor to do it all for it.

12/3/24

Regarding the issue in the paragraph above, I realised that I might be able to make a good system using handler actions (which do multiple actions at once) and signals from actions to signify that their cooldowns are done. I can also lock the inventory from using items until it recieves a done signal from whichever action was used.

While expanding the level generation to include enemies and items, I realised that I might want to define rarities and distributions for how many things should spawn and how much of each. This might be easily achieved using LevelGenSettings resources which can define all of this and give it to the level class.

I think it would be good to start looking into UI for the game, and a good way of doing that might be to start looking at Control nodes to create a debug menu. Being able to do debug operations and view basic info on the game is going to help quite a lot from now, since there are going to be more and more items, effects and enemies.

13/3/24

With the current item system, the inventory is responsible for queueing items once their durabilities have expired, meaning that items which are still in the process of doing their actions are freed before they can complete them. Instead of doing this, the inventory will call the item to be used and the item will report whether or not it should be removed from the inventory. The item is then responsible for freeing itself.
The problem now is that items need to be in the scene tree to function! So I will have inventories maintain a "consumed" node that they can place items in. I will also maintain a node for non-consumed items, for ease of management of items.

Now, I need to decide when to free the item, and while I'm at it, how to do cooldowns. I will make actions emit "finished" signals, and items will not listen for as many "finished" signals as there were actions on call. As a benefit to this system, I can easily create item cooldowns by creating "wait" actions, which simply emit finished after a certain duration.
With this system, I unfortunately have no easy way of defining how long is left of a cooldown, or reducing cooldowns - but I can have each action define an "expected wait time", so that items can visualise how long *might* be left on a cooldown - finished signals may not have actually been emitted yet.

This is also an opportunity to think about buffering inputs on items - this is something that can be handled by the inventory.

14/3/24

I attended the poster day workshop to get an idea of what to make for the poster day, and I was given a few helpful pointers for my use case:
    Make the title accessible and very bait-y: you want feedback and attention from as many people as possible
    Try to avoid too much colour and background to not make the poster too cluttered
    Be aware that black backgrounds are not backlit on a poster - lighter colour schemes are favoured
    Include a link to an itch.io release if possible, for easy feedback - QR code as well
    Keep everything to one or two words. "Questions?" instead of "If you have any questions..."
I will address all of these ahead of the next project meeting to get even more feedback.

Had a thought about the fact that components and effects have pretty much the same utilities and powers: both respond to events sent by the parent entity, and have a process loop of their own. I am still going to keep these things separate, but perhaps port some components to be effects. The distinction between effects and components will be that effects can be added and removed from an entity at a whim.

First things first though, for today, I want to come up with the passive item system for the game, via the effects inventory. The effects container will relay "Add Effect" events to its effects (to allow for stacking behaviours) and if none of them consume the effect, it will add it.

After writing a bit of code for this, I am realising that the systems I've made might need a bit of tweaking to be easy to implement passive items with.
Here are some items that I'd like to create, to ensure flexibility:
    Heal self when killing an enemy (with another entity)
        Effect on host entity must add an effect to created projectiles
            Problem: Melee weapons contained in swing actions do not send ProjectileCreated events
            Problem: Projectiles must know when they have killed something, which is currently not supported.
    Make enemies explode when killed with fire projectiles
        Host entity must add an effect on the fire projectiles - identifying fire projectiles might be qute difficult.
            Problem: See above
    Slow enemies for duration when struck with ice projectiles
        Host entity must once again determine if the projectile is of the ice type and add an on_hit effect to the projectile.
    Make enemies struck by melee attacks bleed
        At this point I'm thinking of instantiating a new knife knife every time for melee weapons. Makes more sense with my system, and it will almost certainly do nothing for performance.
    Make water projectiles bounce once
        This one is pretty easy to do considering collision events, I think, but it might be a little convoluted for what it is.
    Fire a projectile when dashing
        More information needs to be added to the dash event, 

Many of these would benefit from knowing whether or not an entity is a projectile, and from knowing what element a projectile is, so adding that data on the entities is a likely first step. I will then try to implement all of these things.

The only thing that needs a unique solution is projectiles knowing when they have killed something. This might be easily achieved by having entites track what entity dealt damage to them last, and giving them a "Killed Entity" event before dying.
I see some potential issues with the entity technically still being alive when all of this happens, but I will deal with those as I get to them - potentially by running code only when the entity is actually freed?

I feel a big refactor being needed, actions and effects, using Godot's resource system. It's been constantly recommended to me by tutorials and forums, but I was able to make to without it. My issue now is cleanly defining enemies, projectiles, attacks and items without having one or two files for each one. Will have to think on it.

The first item - heal on kill - is extremely convoluted.
The item requires that the projectile has an on-kill effect with a heal-target action. So when a projectile is created by an entity, the relevant heal-on-kill effect needs to add this on-kill effect with the heal action to the projectile.

15/3/24

There is a minor issue with this system - if a fireball with a heal on kill effect hits something and the resulting fire finishes it off, nothing happens. Its up for debate whether or not this should happen, but generally I think kills should be attributed to whoever hit the entity last (maybe up to a time limit). I won't change this for now, however.

My FireVulnerability effect, which is in charge of fire buildup and damage, was originally meant to be called OnFire, and capture other OnFire effect additions to add to fire buildup. I should rename it and give it this behaviour now.
This results in me needing a FireResistance effect to capture OnFire so that they are not added to the EventContainer. 
And the problem is that if an entity that has Fire then has FireResistance, Fire will still intercept and stack effects before FireResistance negates them. Easiest way to deal with this is going to be bundling this information into the Fire Effect instead of having two different ones. No real detriment, easiest solution.

16/3/24

I want to start refactoring active attack items and passive buff items to get their data from a resource, so that actions and effects can look up these attributes in the item's resource. Items only need to store references to these resources, and they will not be dupliicates of eachother.

This lets me easily tag items with any attribute that I want using their resources, and I can autogenerate pickups, descriptions, level gen information and UI in the item's resource rather than in the actual scene for the item. In the resource, I will also have a way to instantiate items directly.

This feels like a pretty significant upgrade to my codebase in terms of performance and being able to define everything as a resource instead of a packed entity, so I'm going to extend this idea to Entities in general and effects, giving me better metadata and type safety.

While I was reimplementing item spawning, Godot corrupted all my ItemResource files and all the scenes that used them, so I had to delete the resources and use a text editor to edit the scenes to fix them myself. Hope that a rollback is not necessary. 
It now detected "infinite recursion" because of a cyclic dependency that was no longer visible in the editor - had to go to tscn files to resolve again.

And later on in the day, Godot threw a hissy fit and detached my script from my node because it didn't like the fact that the _init override had parameters with no defaults. It did not warn me about this, it just silently refused to attach the script at runtime.

20/3/24

After many days of strange errors and a couple of days of rest, I finally have entity metadata, so I can start creating effects that look up this metadata when changing entity atttributes - mostly looking up the type of projectile and its element.

21/3/24

This whole time I've been meaning to add an ice block projectile which spawns as a static object that entities collide with and take damage from if struck by, and this block is going to definetely push my entity component system. 

The block is an opportunity to expand on the library of effects and actions available to entities:
    On death or collision, the block should explode into ice shards 
    It should have a unique hitbox component which multiplies its damage by the block's velocity
    When hit by fire-affinity entities, it should dissappear immediately and turn to a puddle of water

The core of the BSP level generation was easy to implement, but there is a lot to iron out and a lot of utilities to add to the level generator to make generation easy to iterate on and to numerically tweak.
I also have the goal of being able to define prefab tilemaps as children of the level generator scene and have the level generator parse them and copy them into the generate maps, if they fit. 
I also need to add some constraints to the level generation to make sure that rooms are sufficiently large and splitting is done sensibly.

First thing I will do it tear out code from the monolithic level generation function and make more intermediate functions, as this will come in handy for changing things later. The step is to generate partitions, then rooms from those partitions, then populate the rooms, then connect them, and finally to fill the level with walls where applicable.

22/3/24

Godot said it doesnt know what FireEffect is. I restarted the editor. No dice. I renamed it to F**kEffect, and back to FireEffect. Now it works. Happy days.

23/3/24

With most of the frameworky stuff out of the way, its time to crack down hard on game design, so I need to first establish my design objectives:
    Players must have a lot of choice in how they approach an encounter, which would generally come from the spells that they are currently holding.
    Spells should have straightforward offensive traits that get much stronger when used in combination with other spells that deny space, inflict debuffs or control crowds.
    Enemies should be easily readable but powerful relative to the player, so that they player must keep them under control at any given time
    The player should be encouraged to get rid of spells as fast as possible rather than saving them for some opportunity. Spells shouldn't remain with them for longer than a couple of encounters.
    Choices of which spells to use must be interesting and lead to powerful combinations suggested by the player's loadout and passives, as well as enemy placement and types. 
    Choices of which way to go should be interesting, both on the level scale and on a room scale. 

I will attempt to approximate these objectives with a whole load of features which I will develop over the next few days, and then I will assess which are met, which are not, which are rubbish and how to improve them.

I am going to design a whole host of spells and enemy types, as well as a range of passives, and conduct playtesting of my own to see which combinations and runs are most fun, but first I need to decide how the player's inventory and offensive options will be structured.

25/3/24

Remarks on levelgen: 
    Immediately some of the abilities become more interesting since area denial is much more powerful in cramped spaces where enemies already struggle to navigate
    Choke points are incredibly powerful
    Some items are less useful since they are only powerful in large open spaces (like circle of fire)
    It is much more difficult to navigate again, since walls that are part of level templates are difficult to tell from the floor. May be solveable in a postprocessing pass.